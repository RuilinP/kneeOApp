<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>MoveNet Knee Angle Demo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <style>
    body {
      margin: 0;
      background: #111;
      color: #eee;
      font-family: system-ui, sans-serif;
      display: flex;
      flex-direction: column;
      align-items: center;
      min-height: 100vh;
    }
    h2 { margin-top: 12px; }
    #info { font-size: 14px; text-align: center; margin: 4px 8px; }
    video { display: none; }
    canvas { border: 1px solid #444; max-width: 100vw; margin-top: 8px; }
    #angleDisplay { margin-top: 8px; font-size: 18px; }
  </style>
</head>
<body>
  <h2>Knee Angle (Right Leg, MoveNet)</h2>
  <div id="info">
    Sit or stand sideways to the camera so your <b>right</b> leg is visible.<br/>
    Try to fill most of the frame with your body, with good lighting and a plain background.
  </div>

  <video id="video" playsinline></video>
  <canvas id="canvas"></canvas>
  <div id="angleDisplay">Angle: --째</div>

  <!-- TF.js core + WebGL backend -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.20.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs-backend-webgl@4.20.0/dist/tf-backend-webgl.min.js"></script>

  <!-- Pose detection (MoveNet) -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/pose-detection@2.1.3/dist/pose-detection.min.js"></script>

  <script>
    const video = document.getElementById("video");
    const canvas = document.getElementById("canvas");
    const ctx = canvas.getContext("2d");
    const angleDisplay = document.getElementById("angleDisplay");

    let detector = null;
    let currentPose = null;

    // smoothing for angle
    let smoothedAngle = null;
    const SMOOTHING_ALPHA = 0.3;

    // store last good keypoints to bridge short dropouts
    let lastGood = {
      right_hip: null,
      right_knee: null,
      right_ankle: null,
      timestamp: 0
    };
    const MAX_GAP_SEC = 0.3;  // reuse last good for up to 0.3 s

    async function setupCamera() {
      // prefer back camera; fall back to any camera
      const primaryConstraints = {
        video: {
          facingMode: "environment",
          width: { ideal: 480 },
          height: { ideal: 360 }
        },
        audio: false
      };
      const fallbackConstraints = { video: true, audio: false };

      try {
        const stream = await navigator.mediaDevices.getUserMedia(primaryConstraints);
        video.srcObject = stream;
      } catch (e) {
        console.warn("Primary camera failed, using fallback:", e);
        const stream = await navigator.mediaDevices.getUserMedia(fallbackConstraints);
        video.srcObject = stream;
      }

      return new Promise((resolve) => {
        video.onloadedmetadata = () => {
          video.play();
          resolve();
        };
      });
    }

    function getKeypoint(pose, name, minScore = 0.3) {
      if (!pose || !pose.keypoints) return null;
      const kp = pose.keypoints.find(k => k.name === name);
      if (!kp || kp.score < minScore) return null;
      return kp;
    }

    // Reuse last good location if current frame is missing but gap is short
    function getStableKeypoint(pose, name, nowSec, minScore = 0.3) {
      const direct = getKeypoint(pose, name, minScore);
      if (direct) {
        lastGood[name] = { x: direct.x, y: direct.y, score: direct.score };
        lastGood.timestamp = nowSec;
        return direct;
      }
      if (lastGood[name] && (nowSec - lastGood.timestamp) <= MAX_GAP_SEC) {
        return lastGood[name];
      }
      return null;
    }

    function computeKneeAngle(hip, knee, ankle) {
      const v1x = hip.x - knee.x;
      const v1y = hip.y - knee.y;
      const v2x = ankle.x - knee.x;
      const v2y = ankle.y - knee.y;

      const dot = v1x * v2x + v1y * v2y;
      const mag1 = Math.hypot(v1x, v1y);
      const mag2 = Math.hypot(v2x, v2y);
      if (mag1 === 0 || mag2 === 0) return null;

      const cosTheta = dot / (mag1 * mag2);
      const clamped = Math.min(1, Math.max(-1, cosTheta));
      const angleRad = Math.acos(clamped);
      return (angleRad * 180) / Math.PI;
    }

    function drawSkeleton(pose) {
      if (!pose) return;
      const kp = pose.keypoints;

      kp.forEach(k => {
        if (k.score > 0.3) {
          ctx.beginPath();
          ctx.arc(k.x, k.y, 4, 0, 2 * Math.PI);
          ctx.fillStyle = "cyan";
          ctx.fill();
        }
      });

      const rh = getKeypoint(pose, "right_hip", 0.3);
      const rk = getKeypoint(pose, "right_knee", 0.3);
      const ra = getKeypoint(pose, "right_ankle", 0.3);

      ctx.strokeStyle = "yellow";
      ctx.lineWidth = 3;
      if (rh && rk) {
        ctx.beginPath();
        ctx.moveTo(rh.x, rh.y);
        ctx.lineTo(rk.x, rk.y);
        ctx.stroke();
      }
      if (rk && ra) {
        ctx.beginPath();
        ctx.moveTo(rk.x, rk.y);
        ctx.lineTo(ra.x, ra.y);
        ctx.stroke();
      }
    }

    function updateAngleDisplay(pose) {
      const nowSec = performance.now() / 1000;

      const hip   = getStableKeypoint(pose, "right_hip",   nowSec);
      const knee  = getStableKeypoint(pose, "right_knee",  nowSec);
      const ankle = getStableKeypoint(pose, "right_ankle", nowSec);

      if (!hip || !knee || !ankle) {
        angleDisplay.textContent = "Angle: --째 (right leg not clearly detected)";
        return;
      }

      let angle = computeKneeAngle(hip, knee, ankle);
      if (angle == null || isNaN(angle)) {
        angleDisplay.textContent = "Angle: --째 (invalid)";
        return;
      }

      if (smoothedAngle == null) smoothedAngle = angle;
      smoothedAngle =
        SMOOTHING_ALPHA * angle + (1 - SMOOTHING_ALPHA) * smoothedAngle;

      angleDisplay.textContent = `Angle: ${smoothedAngle.toFixed(1)}째`;
    }

    async function main() {
      await setupCamera();
      canvas.width  = video.videoWidth;
      canvas.height = video.videoHeight;

      await tf.setBackend("webgl");
      await tf.ready();

      const model = poseDetection.SupportedModels.MoveNet;
      const detectorConfig = {
        modelType: poseDetection.movenet.modelType.SINGLEPOSE_LIGHTNING,
        enableSmoothing: true
      };
      detector = await poseDetection.createDetector(model, detectorConfig);

      async function renderLoop() {
        const poses = await detector.estimatePoses(video, {
          maxPoses: 1,
          flipHorizontal: true
        });
        currentPose = poses[0] || null;

        ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
        drawSkeleton(currentPose);
        updateAngleDisplay(currentPose);

        requestAnimationFrame(renderLoop);
      }

      renderLoop();
    }

    main().catch(err => {
      console.error(err);
      angleDisplay.textContent = "Error: " + err.message;
    });
  </script>
</body>
</html>
